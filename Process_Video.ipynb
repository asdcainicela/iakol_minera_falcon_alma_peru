{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQyC0cTwSiCv"
   },
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2467,
     "status": "ok",
     "timestamp": 1752255286787,
     "user": {
      "displayName": "Gerald Cain",
      "userId": "07510965010433277448"
     },
     "user_tz": 300
    },
    "id": "dWMDZr2F7Hrd",
    "outputId": "1235a0b8-d1cc-47d2-ae8a-878d9b7833be"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/Smartech/MinaRumas')\n",
    "sys.path.append('/content/drive/MyDrive/Smartech/MinaRumas/libs')\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/Smartech/MinaRumas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sa1TW7HnSec_"
   },
   "source": [
    "# Install paquetes python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZkFtZhoU6vh"
   },
   "source": [
    "## install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4197,
     "status": "ok",
     "timestamp": 1752255290988,
     "user": {
      "displayName": "Gerald Cain",
      "userId": "07510965010433277448"
     },
     "user_tz": 300
    },
    "id": "d0ku_ICCSdeZ",
    "outputId": "0a7d251d-3eec-45f9-f084-4c3d4bbf18b7"
   },
   "outputs": [],
   "source": [
    "%pip install ultralytics\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2rQCYe3-Sj-o"
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1752255291018,
     "user": {
      "displayName": "Gerald Cain",
      "userId": "07510965010433277448"
     },
     "user_tz": 300
    },
    "id": "GCQqmvuQUtwn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import base64\n",
    "import torch\n",
    "import requests\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "#Import librerias propias\n",
    "from monitor.ruma_monitor import RumaMonitor\n",
    "from utils.paths import generar_ruta_salida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wU7slVuGStDq"
   },
   "source": [
    "# Ruma logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKk1uNh9Tiwl"
   },
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUqHQ209Tg7y"
   },
   "source": [
    "## Logic class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EmaW4xgxS0OT"
   },
   "source": [
    "# Process video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1752255291021,
     "user": {
      "displayName": "Gerald Cain",
      "userId": "07510965010433277448"
     },
     "user_tz": 300
    },
    "id": "7CRsiK6Dp7pe"
   },
   "outputs": [],
   "source": [
    "def process_video(video_path, output_path, start_time_sec, end_time_sec,\n",
    "                 model_det_path, model_seg_path, detection_zone, camera_number):\n",
    "    \"\"\"\n",
    "    Procesa un video completo usando el monitor de rumas\n",
    "\n",
    "    Args:\n",
    "        video_path: Ruta del video de entrada\n",
    "        output_path: Ruta del video de salida\n",
    "        start_time_sec: Tiempo de inicio en segundos\n",
    "        end_time_sec: Tiempo de fin en segundos\n",
    "        model_det_path: Ruta del modelo de detección\n",
    "        model_seg_path: Ruta del modelo de segmentación\n",
    "        detection_zone: Zona de detección como array numpy\n",
    "        camera_number: Número de cámara (1, 2, o 3)\n",
    "    \"\"\"\n",
    "\n",
    "    # Mapear número de cámara a serial\n",
    "    camera_serials = {\n",
    "        1: \"DS-7104NI-Q1-1\",\n",
    "        2: \"DS-7104NI-Q1-2\",\n",
    "        3: \"DS-7104NI-Q1-3\"\n",
    "    }\n",
    "\n",
    "    camera_sn = camera_serials.get(camera_number, \"DS-7104NI-Q1-1\")\n",
    "\n",
    "    # Inicializar monitor\n",
    "    monitor = RumaMonitor(model_det_path, model_seg_path, detection_zone, camera_sn)\n",
    "\n",
    "    # Configurar video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    print(f\"Video: {width}x{height} @ {fps} FPS\")\n",
    "\n",
    "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "    start_frame = int(start_time_sec * fps)\n",
    "    end_frame = int(end_time_sec * fps)\n",
    "\n",
    "    print(f\"Procesando frames {start_frame} a {end_frame}\")\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret or frame_count > end_frame:\n",
    "                break\n",
    "\n",
    "            if frame_count >= start_frame:\n",
    "                # Procesar frame\n",
    "                processed_frame = monitor.process_frame(frame, frame_count, fps)\n",
    "                out.write(processed_frame)\n",
    "\n",
    "                # Progreso\n",
    "                if frame_count % 50 == 0:\n",
    "                    print(f\"Procesados {frame_count} frames\")\n",
    "                    print(f\"Rumas activas: {sum(1 for r in monitor.rumas.values() if r.is_active)}\")\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Procesamiento completado. Video guardado en {output_path}\")\n",
    "    print(f\"Total de rumas detectadas: {len(monitor.rumas)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVr4brZaTFCV"
   },
   "source": [
    "# Uso de lógica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 931
    },
    "executionInfo": {
     "elapsed": 27056,
     "status": "error",
     "timestamp": 1752255318078,
     "user": {
      "displayName": "Gerald Cain",
      "userId": "07510965010433277448"
     },
     "user_tz": 300
    },
    "id": "5LTLU6_cp_mf",
    "outputId": "5ff4ac9d-263a-45bf-c7c0-e90a8d085e01"
   },
   "outputs": [],
   "source": [
    "# Process video, no --\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = 'video/video_cam3_0422.mp4'\n",
    "    output_path = generar_ruta_salida(video_path)\n",
    "    start_time_sec = 0# 10\n",
    "    end_time_sec =120 # 100\n",
    "\n",
    "    model_det_path = 'models/model_detection.pt'\n",
    "    model_seg_path = 'models/model_segmentation.pt'\n",
    "\n",
    "    camera_number = 3  # Cambiar según la cámara\n",
    "\n",
    "    if camera_number ==1: ## donde la ruma estan esparcidas en un campo\n",
    "      detection_zone = np.array([\n",
    "          [20, 691], [18, 779], [414, 881], [709, 759],\n",
    "          [1675, 1060], [1902, 890], [1902, 667], [704, 416]\n",
    "          ], np.int32) # Cambiar las coordenadas de las zonas segun la camara, input de process_video (se puede setear en un .yml)\n",
    "    elif camera_number ==2: # se puede ver la escalera o faja\n",
    "      detection_zone = np.array([\n",
    "          [1740,533],[1788,1075],[741,1074],[433,591],[400,480],[536,442],[1008,365],[1061,398],[1128,389],[1214,431],[1369,397]\n",
    "          ], np.int32) # Cambiar las coordenadas de las zonas segun la camara, input de process_video (se puede setear en un .yml)\n",
    "    elif camera_number ==3:\n",
    "      detection_zone = np.array([\n",
    "          [1862,767],[1443,633],[794,1077],[123,1072],[3,711],[4,517],[1122,256],[1893,450],[1860,534],[1873,611],[1855,689]\n",
    "          ], np.int32) # Cambiar las coordenadas de las zonas segun la camara, input de process_video (se puede setear en un .yml)\n",
    "\n",
    "\n",
    "    process_video(\n",
    "        video_path, output_path, start_time_sec, end_time_sec,\n",
    "        model_det_path, model_seg_path, detection_zone, camera_number\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "BQyC0cTwSiCv",
    "kZkFtZhoU6vh"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
